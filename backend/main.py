"""
í•œêµ­ì–´ NLP ì˜ë¯¸ì  ì—°ê´€ ë„¤íŠ¸ì›Œí¬ - FastAPI ë°±ì—”ë“œ
ì‹¤ì œ KoSentenceBERT, Word2Vec, ConceptNet í™œìš©
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Any
import uvicorn
import asyncio
import httpx
import logging
from datetime import datetime

from nlp_models import (
    KoreanNLPManager,
    SemanticSimilarityCalculator,
    ClusteringEngine,
    GPTLabeler
)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="Korean NLP Semantic Network API",
    description="ì‹¤ì‹œê°„ í•œêµ­ì–´ ì˜ë¯¸ì  ì—°ê´€ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ API",
    version="1.0.0"
)

# CORS ì„¤ì • (í”„ë¡ íŠ¸ì—”ë“œ ì—°ê²°)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ê°œë°œìš© - ì‹¤ì œ ë°°í¬ì‹œ íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì „ì—­ NLP ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
nlp_manager = None
similarity_calculator = None
clustering_engine = None
gpt_labeler = None

# ìš”ì²­/ì‘ë‹µ ëª¨ë¸ ì •ì˜
class WordRequest(BaseModel):
    word: str

class WordPairRequest(BaseModel):
    word1: str
    word2: str

class ClusteringRequest(BaseModel):
    words: List[str]
    num_clusters: int = 3

class LabelingRequest(BaseModel):
    words: List[str]

class HealthResponse(BaseModel):
    status: str
    timestamp: str
    sbert_loaded: bool
    word2vec_loaded: bool
    conceptnet_available: bool
    gpt_available: bool

class VectorResponse(BaseModel):
    word: str
    vector: List[float]
    method: str

class SimilarityResponse(BaseModel):
    word1: str
    word2: str
    similarity: float
    method: str
    confidence: str

class HybridSimilarityResponse(BaseModel):
    word1: str
    word2: str
    hybrid_score: float
    vector_similarity: float
    llm_similarity: float
    conceptnet_score: float
    confidence: str

class ClusteringResponse(BaseModel):
    words: List[str]
    cluster_assignments: List[int]
    silhouette_score: float
    method: str

class LabelingResponse(BaseModel):
    words: List[str]
    label: str
    confidence: float

# ì‹œì‘ ì´ë²¤íŠ¸ - NLP ëª¨ë¸ ë¡œë”©
@app.on_event("startup")
async def startup_event():
    global nlp_manager, similarity_calculator, clustering_engine, gpt_labeler
    
    logger.info("ğŸš€ í•œêµ­ì–´ NLP ë°±ì—”ë“œ ì‹œì‘ ì¤‘...")
    
    try:
        # NLP ë§¤ë‹ˆì € ì´ˆê¸°í™” (ëª¨ë¸ ë¡œë”©)
        logger.info("ğŸ“¦ KoSentenceBERT ë° Word2Vec ëª¨ë¸ ë¡œë”© ì¤‘...")
        nlp_manager = KoreanNLPManager()
        await nlp_manager.initialize_models()
        
        # ìœ ì‚¬ë„ ê³„ì‚°ê¸° ì´ˆê¸°í™”
        logger.info("ğŸ” ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚°ê¸° ì´ˆê¸°í™” ì¤‘...")
        similarity_calculator = SemanticSimilarityCalculator(nlp_manager)
        
        # í´ëŸ¬ìŠ¤í„°ë§ ì—”ì§„ ì´ˆê¸°í™”
        logger.info("ğŸ¯ í´ëŸ¬ìŠ¤í„°ë§ ì—”ì§„ ì´ˆê¸°í™” ì¤‘...")
        clustering_engine = ClusteringEngine(nlp_manager)
        
        # GPT ë¼ë²¨ëŸ¬ ì´ˆê¸°í™”
        logger.info("ğŸ¤– GPT ë¼ë²¨ëŸ¬ ì´ˆê¸°í™” ì¤‘...")
        gpt_labeler = GPTLabeler()
        
        logger.info("âœ… ëª¨ë“  NLP ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
        
    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        # ë¶€ë¶„ì  ë¡œë”©ë„ í—ˆìš© (ì„œë¹„ìŠ¤ ì§€ì†ì„±)

# ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸
@app.get("/api/health", response_model=HealthResponse)
async def health_check():
    """ì‹œìŠ¤í…œ ìƒíƒœ ë° ëª¨ë¸ ë¡œë”© ìƒíƒœ í™•ì¸"""
    
    # ConceptNet ì—°ê²° í…ŒìŠ¤íŠ¸
    conceptnet_available = False
    try:
        async with httpx.AsyncClient(timeout=3.0) as client:
            response = await client.get("https://api.conceptnet.io/c/ko/í…ŒìŠ¤íŠ¸")
            conceptnet_available = response.status_code == 200
    except:
        pass
    
    return HealthResponse(
        status="healthy" if nlp_manager else "partial",
        timestamp=datetime.now().isoformat(),
        sbert_loaded=nlp_manager.sbert_model is not None if nlp_manager else False,
        word2vec_loaded=nlp_manager.word2vec_model is not None if nlp_manager else False,
        conceptnet_available=conceptnet_available,
        gpt_available=gpt_labeler.is_available if gpt_labeler else False
    )

# ë‹¨ì–´ ë²¡í„°í™” ì—”ë“œí¬ì¸íŠ¸
@app.post("/api/vectorize", response_model=VectorResponse)
async def vectorize_word(request: WordRequest):
    """í•œêµ­ì–´ ë‹¨ì–´ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ (KoSentenceBERT)"""
    
    if not nlp_manager:
        raise HTTPException(status_code=503, detail="NLP ëª¨ë¸ì´ ë¡œë”©ë˜ì§€ ì•ŠìŒ")
    
    try:
        vector, method = await nlp_manager.get_word_vector(request.word)
        
        return VectorResponse(
            word=request.word,
            vector=vector.tolist() if hasattr(vector, 'tolist') else vector,
            method=method
        )
        
    except Exception as e:
        logger.error(f"ë²¡í„°í™” ì‹¤íŒ¨ - {request.word}: {e}")
        raise HTTPException(status_code=500, detail=f"ë²¡í„°í™” ì‹¤íŒ¨: {str(e)}")

# ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚° ì—”ë“œí¬ì¸íŠ¸
@app.post("/api/semantic-similarity", response_model=SimilarityResponse)
async def calculate_semantic_similarity(request: WordPairRequest):
    """ë‘ í•œêµ­ì–´ ë‹¨ì–´ì˜ ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚°"""
    
    if not similarity_calculator:
        raise HTTPException(status_code=503, detail="ìœ ì‚¬ë„ ê³„ì‚°ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
    
    try:
        similarity, method, confidence = await similarity_calculator.calculate_similarity(
            request.word1, request.word2
        )
        
        return SimilarityResponse(
            word1=request.word1,
            word2=request.word2,
            similarity=similarity,
            method=method,
            confidence=confidence
        )
        
    except Exception as e:
        logger.error(f"ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨ - {request.word1} vs {request.word2}: {e}")
        raise HTTPException(status_code=500, detail=f"ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")

# í•˜ì´ë¸Œë¦¬ë“œ ìœ ì‚¬ë„ ê³„ì‚° ì—”ë“œí¬ì¸íŠ¸
@app.post("/api/hybrid-similarity", response_model=HybridSimilarityResponse)
async def calculate_hybrid_similarity(request: WordPairRequest):
    """ë‹¤ì¤‘ ë°©ë²•ë¡ ì„ í™œìš©í•œ í•˜ì´ë¸Œë¦¬ë“œ ìœ ì‚¬ë„ ê³„ì‚°"""
    
    if not similarity_calculator:
        raise HTTPException(status_code=503, detail="ìœ ì‚¬ë„ ê³„ì‚°ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
    
    try:
        result = await similarity_calculator.calculate_hybrid_similarity(
            request.word1, request.word2
        )
        
        return HybridSimilarityResponse(
            word1=request.word1,
            word2=request.word2,
            hybrid_score=result['hybrid_score'],
            vector_similarity=result['vector_similarity'],
            llm_similarity=result['llm_similarity'],
            conceptnet_score=result['conceptnet_score'],
            confidence=result['confidence']
        )
        
    except Exception as e:
        logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨ - {request.word1} vs {request.word2}: {e}")
        raise HTTPException(status_code=500, detail=f"í•˜ì´ë¸Œë¦¬ë“œ ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")

# í´ëŸ¬ìŠ¤í„°ë§ ì—”ë“œí¬ì¸íŠ¸
@app.post("/api/clustering", response_model=ClusteringResponse)
async def perform_clustering(request: ClusteringRequest):
    """K-means ê¸°ë°˜ ì˜ë¯¸ì  í´ëŸ¬ìŠ¤í„°ë§"""
    
    if not clustering_engine:
        raise HTTPException(status_code=503, detail="í´ëŸ¬ìŠ¤í„°ë§ ì—”ì§„ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
    
    if len(request.words) < 2:
        raise HTTPException(status_code=400, detail="í´ëŸ¬ìŠ¤í„°ë§í•˜ë ¤ë©´ ìµœì†Œ 2ê°œ ì´ìƒì˜ ë‹¨ì–´ê°€ í•„ìš”")
    
    try:
        # í´ëŸ¬ìŠ¤í„° ìˆ˜ ìë™ ì¡°ì •
        optimal_clusters = min(request.num_clusters, len(request.words) // 2 + 1)
        
        cluster_assignments, silhouette_score, method = await clustering_engine.perform_clustering(
            request.words, optimal_clusters
        )
        
        return ClusteringResponse(
            words=request.words,
            cluster_assignments=cluster_assignments,
            silhouette_score=silhouette_score,
            method=method
        )
        
    except Exception as e:
        logger.error(f"í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨ - {request.words}: {e}")
        raise HTTPException(status_code=500, detail=f"í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨: {str(e)}")

# GPT ë¼ë²¨ë§ ì—”ë“œí¬ì¸íŠ¸
@app.post("/api/generate-labels", response_model=LabelingResponse)
async def generate_cluster_labels(request: LabelingRequest):
    """OpenAI GPTë¥¼ í™œìš©í•œ í´ëŸ¬ìŠ¤í„° ë¼ë²¨ ìƒì„±"""
    
    if not gpt_labeler:
        raise HTTPException(status_code=503, detail="GPT ë¼ë²¨ëŸ¬ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
    
    if len(request.words) == 0:
        raise HTTPException(status_code=400, detail="ë¼ë²¨ë§í•  ë‹¨ì–´ê°€ ì—†ìŒ")
    
    try:
        label, confidence = await gpt_labeler.generate_label(request.words)
        
        return LabelingResponse(
            words=request.words,
            label=label,
            confidence=confidence
        )
        
    except Exception as e:
        logger.error(f"GPT ë¼ë²¨ë§ ì‹¤íŒ¨ - {request.words}: {e}")
        
        # GPT ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ë¼ë²¨ ìƒì„±
        fallback_label = f"ğŸ“Š {len(request.words)}ê°œ ë‹¨ì–´ ê·¸ë£¹"
        
        return LabelingResponse(
            words=request.words,
            label=fallback_label,
            confidence=0.3
        )

# ConceptNet ì¿¼ë¦¬ ì—”ë“œí¬ì¸íŠ¸
@app.post("/api/conceptnet-query")
async def query_conceptnet(request: WordPairRequest):
    """ConceptNet APIë¥¼ í†µí•œ ê°œë… ê´€ê³„ ì¡°íšŒ"""
    
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            url = f"https://api.conceptnet.io/relatedness"
            params = {
                "node1": f"/c/ko/{request.word1}",
                "node2": f"/c/ko/{request.word2}"
            }
            
            response = await client.get(url, params=params)
            
            if response.status_code == 200:
                data = response.json()
                return {
                    "word1": request.word1,
                    "word2": request.word2,
                    "relatedness": data.get("value", 0.0),
                    "source": "conceptnet"
                }
            else:
                raise HTTPException(status_code=response.status_code, detail="ConceptNet API ì˜¤ë¥˜")
                
    except Exception as e:
        logger.error(f"ConceptNet ì¿¼ë¦¬ ì‹¤íŒ¨ - {request.word1} vs {request.word2}: {e}")
        raise HTTPException(status_code=500, detail=f"ConceptNet ì¿¼ë¦¬ ì‹¤íŒ¨: {str(e)}")

# ì„œë²„ ì‹¤í–‰ í•¨ìˆ˜
if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,  # ê°œë°œ ëª¨ë“œ
        log_level="info"
    )
